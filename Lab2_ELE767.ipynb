{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1EXnuuDCsLLbGae-ECRl-XQi-LP-kg-hf",
      "authorship_tag": "ABX9TyPPxAcGdkaXOB1+dXQq108n",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/samsas556/ELE400Pitot_Omer/blob/main/Lab2_ELE767.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "9IYlbYrIbQWG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "outputId": "805a50a7-67b7-46ef-d25a-cb7eaa37f8e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "662/712 [==========================>...] - ETA: 0s - loss: 2.3715 - accuracy: 0.1178"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-836de266de48>\u001b[0m in \u001b[0;36m<cell line: 182>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0mmlp3c\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m'SGD'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparseCategoricalCrossentropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmlp3c\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_set\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoque\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m     \u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;34m\" Apprentissage d’un MLP a 2 couche avec abandon pour la classification des signaux sonores \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-24-836de266de48>\u001b[0m in \u001b[0;36mtraining\u001b[0;34m(model, data_ds, epochs, n_fold, verbose_train, verbose_test)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;31m# Evaluer le modele avant l’ entrainement\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0mevaluate\u001b[0m \u001b[0;34m(\u001b[0m \u001b[0mtrain_set\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mverbose_train\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m   \u001b[0mtrain_accuracy\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0mappend\u001b[0m \u001b[0;34m(\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m   \u001b[0mtrain_loss\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0mappend\u001b[0m \u001b[0;34m(\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   2294\u001b[0m                         ):\n\u001b[1;32m   2295\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2296\u001b[0;31m                             logs = test_function_runner.run_step(\n\u001b[0m\u001b[1;32m   2297\u001b[0m                                 \u001b[0mdataset_or_iterator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2298\u001b[0m                                 \u001b[0mdata_handler\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mrun_step\u001b[0;34m(self, dataset_or_iterator, data_handler, step, unused_shards)\u001b[0m\n\u001b[1;32m   4106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4107\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_or_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munused_shards\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4108\u001b[0;31m         \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_or_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4109\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4110\u001b[0m             \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    866\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m       return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    869\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1321\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1322\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1487\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "from sklearn . model_selection import KFold\n",
        "\n",
        "mode = 3 #0= perceptron, 1=MLP a 2 couche , 2= MLP a 2 couche avec abandon , 3= MLP a 3 couche, 4=modele au choix\n",
        "\n",
        "validation_mystere = 0 # verifie les donne mystere avec la configuration du mode choisis\n",
        "\n",
        "epoque = 15\n",
        "\n",
        "\n",
        "def training( model , data_ds , epochs =10 , n_fold =5 , verbose_train =1 , verbose_test=1) :\n",
        "  \"\"\"\n",
        "  TRAINING\n",
        "  Fonction servant a entrainer un model et en verifiant les capacites du modele\n",
        "  sur les donnees de test\n",
        "  @Arguments :\n",
        "    model { tensorflow . python . keras . engine . sequential . Sequential } : Modele\n",
        "    tensorflow a entrainer\n",
        "    data_ds {pd. DataFrame } : Base de donnees d’ entrainement\n",
        "    epochs { int } : Nombre d’epoques a faire pour l’ entrainement du model\n",
        "    n_fold { int } : Nombre de fold pour le kfold\n",
        "    verbose_train { int } : 1 pour afficher l’avancement de l’apprentissage ,\n",
        "    0 aucun affichage\n",
        "    verbose_test { int} : 1 pour afficher l’avancement de l’evaluation ,\n",
        "    0 aucun affichage\n",
        "    @Return :\n",
        "    { dict } : ’ train_accuracy ’ { list } : liste de la precision du modele sur la\n",
        "    base de donnees d’ entrainement\n",
        "    ’train_loss ’ { list } : liste des resultat de la fonction de\n",
        "    perte du modele sur la base de donnees d’ entrainement\n",
        "    ’ test_accuracy ’ { list } : liste de la precision du modele sur\n",
        "    la base de donnees de test\n",
        "    ’test_loss ’ { list } : liste des resultats de la fonction de\n",
        "    perte du modele sur la base de donnees de test\n",
        "  \"\"\"\n",
        "  # Initialisation des listes recevants\n",
        "  train_accuracy = []\n",
        "  train_loss = []\n",
        "  test_accuracy = []\n",
        "  test_loss = []\n",
        "\n",
        "  # Creer les bases de donnees pour l’ entrainement\n",
        "  train_set , test_set = create_sets ( data_ds , n_fold )\n",
        "\n",
        "  # Evaluer le modele avant l’ entrainement\n",
        "  result = model . evaluate ( train_set , verbose = verbose_train )\n",
        "  train_accuracy . append ( result [1])\n",
        "  train_loss . append ( result [0])\n",
        "  # ---\n",
        "  result = model . evaluate ( test_set , verbose = verbose_test )\n",
        "  test_accuracy . append ( result [1])\n",
        "  test_loss . append ( result [0])\n",
        "\n",
        "  # Boucle d’ entrainement\n",
        "\n",
        "  for e in range(epochs):\n",
        "    print ('Epoch #{} '.format(e +1))\n",
        "    # ---\n",
        "    result = model.fit(train_set , epochs=1 , verbose = verbose_train)\n",
        "    train_accuracy.append( result.history['accuracy'][-1])\n",
        "    train_loss.append(result.history['loss'][-1])\n",
        "    # ---\n",
        "    result = model.evaluate( test_set , verbose = verbose_test )\n",
        "    test_accuracy.append( result[1])\n",
        "    test_loss.append( result[0])\n",
        "\n",
        "  return {'train_accuracy': train_accuracy ,\n",
        "          'train_loss': train_loss ,\n",
        "          'test_accuracy': test_accuracy ,\n",
        "          'test_loss': test_loss }\n",
        "\n",
        "def figure( training_dict , suptitle , figsize =(12 ,6) ):\n",
        "  \"\"\"\n",
        "  FIGURE\n",
        "  Produit une figure avec les statistiques de la fonction ’training ’\n",
        "  @Arguments :\n",
        "  training_dict { dict ( list )} : Dictionnaire retournee par la fonction\n",
        "  training\n",
        "  figsize { Tuple } : Dimension de la figure\n",
        "  \"\"\"\n",
        "  global mode\n",
        "\n",
        "  # Demarre une figure avec la taille (en pouce ) donner en arguments\n",
        "  plt.figure(figsize = figsize , facecolor ='w')\n",
        "  # Titre global de la figure\n",
        "  plt.suptitle( suptitle )\n",
        "  # Premiere sous - figure -> Precision du modele durant l’ entrainement\n",
        "  plt.subplot(121)\n",
        "  plt.title('Precision du modele ')\n",
        "  plt.xlabel('Nombre d\\' epoques ')\n",
        "  plt.ylabel('Precision de la classification ')\n",
        "  # Produit une courbe pour chaque base de donnees\n",
        "  plt.plot(training_dict['train_accuracy'], 'r', label ='training')\n",
        "  plt.plot(training_dict['test_accuracy'], 'y', label ='test')\n",
        "  # Limite de la precision pour rendre les valeurs entre 0% et 100% visibles\n",
        "  plt.ylim(0 ,1.01)\n",
        "  # Produire un grille en arriere - plan\n",
        "  #plt.grid(b=True , which ='major', color = '#666666 ' , linestyle = '-')\n",
        "  plt.grid()\n",
        "  plt.minorticks_on()\n",
        "  #plt.grid(b= True , which ='minor ', color ='#999999 ', linestyle ='-', alpha =0.2)\n",
        "  plt.legend() # Afficher les labels des courbes\n",
        "  # Deuxieme sous - figure -> Resultat de la fonction de perte durant l’entrainement\n",
        "  plt.subplot(122)\n",
        "  plt.title('Perte du modele ')\n",
        "  plt.xlabel('Nombre d\\' epoques ')\n",
        "  plt.ylabel('Resultat de la fonction de perte')\n",
        "  # Produire une courbe pour chaque base de donnees\n",
        "  plt.plot(training_dict['train_loss'],'r', label ='training')\n",
        "  plt.plot(training_dict['test_loss'],'y', label ='test');\n",
        "  # S’assurer que la valeur minimum de l’ordonnee soit 0\n",
        "  plt.ylim(0);\n",
        "  # Produire un grille en arriere - plan\n",
        "  #plt.grid(b=True , which ='major', color = '#666666 ' , linestyle =  '-')\n",
        "  plt.grid()\n",
        "  plt.minorticks_on()\n",
        "  #plt.grid(b= True , which ='minor', color ='#999999 ', linestyle ='-', alpha =0.2)\n",
        "  plt.legend()\n",
        "\n",
        "  if mode==0:\n",
        "    plt.savefig(\"graph_perceptron.png\")\n",
        "  elif mode ==1:\n",
        "    plt.savefig(\"graph_MLP2c.png\")\n",
        "  elif mode ==2:\n",
        "    plt.savefig(\"graph_MLP2dropout.png\")\n",
        "  elif mode ==3:\n",
        "    plt.savefig(\"graph_MLP3c.png\")\n",
        "  return\n",
        "\n",
        "def create_sets(data_ds, n_fold =5):\n",
        "  \"\"\"\n",
        "  CREATE_SETS\n",
        "    Transforme les bases de donnees afin d’etre compatible avec l’ entrainement\n",
        "    du modele avec la methode \" fit \"\n",
        "  @Arguments :\n",
        "    data_ds {pd. DataFrame } : Base de donnees d’ entrainement\n",
        "    n_fold { int } : nombre de division pour le kfold\n",
        "  @Return :\n",
        "    { tensorflow.BatchDataset } : Base de donnees d’ entrainement\n",
        "    { tensorflow.BatchDataset } : Base de donnees de test\n",
        "  \"\"\"\n",
        "  # Melanger les valeurs de la base de donnees\n",
        "  data = data_ds.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "  # Diviser les variables et les resultats\n",
        "  data_output = data.pop(\"number\")\n",
        "\n",
        "  # Extraire les indexes pour le kfold une seule fois\n",
        "  for train_index , test_index in KFold( n_fold ).split( data ) :\n",
        "    # Creer la base de donnees d’ entrainement\n",
        "    X_train = (data.values)[train_index]\n",
        "    y_train = (data_output.values )[train_index]\n",
        "    ### Creer la base de donnees de test\n",
        "    X_test = (data.values) [test_index]\n",
        "    y_test = (data_output.values)[test_index]\n",
        "    break\n",
        "\n",
        "  # Transformer les bases de donnees pour etre utilisees directement dans fit\n",
        "  # Les donnees sont melangees une autre fois avant d’etre retournees\n",
        "  train_set = tf.data.Dataset.from_tensor_slices((X_train,y_train))\n",
        "  train_set = train_set.shuffle(len(X_train))\n",
        "  train_set = train_set.batch(1)\n",
        "\n",
        "  test_set = tf.data.Dataset.from_tensor_slices((X_test,y_test))\n",
        "  test_set = test_set.shuffle(len(X_test))\n",
        "  test_set = test_set.batch(1)\n",
        "\n",
        "  return train_set , test_set\n",
        "\n",
        "\n",
        "#============================main code =============================#\n",
        "\n",
        "\n",
        "data_set = pd.read_csv(\"data.csv\")\n",
        "\n",
        "\n",
        "if validation_mystere ==1:\n",
        "\n",
        "  _mystere_ds = pd.read_csv(\"mystere.csv\")\n",
        "  print(_mystere_ds.info())\n",
        "  mystere_ds = tf.data. Dataset.from_tensor_slices(_mystere_ds.values)\n",
        "  mystere_set = mystere_ds.batch(1)\n",
        "\n",
        "  result = []\n",
        "\n",
        "  for model_dir in ['modeles/perceptron','modeles/mlp2','modeles/mlp2Dropout','modeles/mlp3']:\n",
        "    model = tf.keras.models.load_model(model_dir)\n",
        "    prediction = model.predict(mystere_set)\n",
        "    # Retourne l’index ayant la plus grande valeur\n",
        "    result.append( np.argmax(prediction , axis =1))\n",
        "\n",
        "\n",
        "  # Transferer la liste en array de numpy\n",
        "  result = np.array(result)\n",
        "  # Afficher les resultats\n",
        "  print(\" Resultat de tous les modeles \")\n",
        "  print(result)\n",
        "  print(\" Resultat commun entre les modeles \")\n",
        "  print((stats.mode(result,axis =0)) [0])\n",
        "\n",
        "elif validation_mystere ==0:\n",
        "\n",
        "  if mode==0:\n",
        "    # Creer un modele sequentiel\n",
        "    perceptron = tf.keras.Sequential([layers.Dense(4 , activation='sigmoid', dtype ='float64')])\n",
        "    # Compiler le modele pour l’ entrainement\n",
        "    perceptron.compile(optimizer ='SGD',loss = tf.keras.losses.SparseCategoricalCrossentropy() ,metrics =['accuracy'])\n",
        "\n",
        "    result_perceptron = training(perceptron,data_set,epochs=epoque)\n",
        "    figure( result_perceptron , \" Apprentissage d’un perceptron pour la classification des signaux sonores \")\n",
        "\n",
        "    perceptron.save('modeles/perceptron')\n",
        "\n",
        "  elif mode==1:\n",
        "\n",
        "    mlp2c = tf.keras.Sequential([\n",
        "    layers.Dense(512 , activation ='sigmoid', dtype ='float64'),\n",
        "    layers.Dense(10 , activation ='sigmoid', dtype ='float64')])\n",
        "\n",
        "    # Compiler le modele pour l’ entrainement\n",
        "    mlp2c.compile( optimizer ='SGD',loss = tf.keras.losses.SparseCategoricalCrossentropy(),metrics =['accuracy'])\n",
        "\n",
        "    result = training(mlp2c,data_set,epochs=epoque)\n",
        "    figure(result , \" Apprentissage d’un MLP a 2 couche pour la classification des signaux sonores \")\n",
        "\n",
        "    mlp2c.save('modeles/mlp2')\n",
        "\n",
        "  elif mode==2:\n",
        "\n",
        "    mlp2c = tf.keras.Sequential([\n",
        "    layers.Dense(512 , activation ='sigmoid', dtype ='float64'),\n",
        "    layers.Dense(10 , activation ='sigmoid', dtype ='float64')])\n",
        "    layers.Dropout(0.2 , dtype ='float64')\n",
        "\n",
        "    # Compiler le modele pour l’ entrainement\n",
        "    mlp2c.compile( optimizer ='SGD',loss = tf.keras.losses.SparseCategoricalCrossentropy(),metrics =['accuracy'])\n",
        "\n",
        "    result = training(mlp2c,data_set,epochs=epoque)\n",
        "    figure(result , \" Apprentissage d’un MLP a 2 couche avec abandon pour la classification des signaux sonores \")\n",
        "\n",
        "    mlp2c.save('modeles/mlp2Dropout')\n",
        "\n",
        "  elif mode==3:\n",
        "\n",
        "    mlp3c = tf.keras.Sequential([\n",
        "            layers.Dense(512 , activation ='relu', dtype ='float64') ,\n",
        "            layers.Dense(128 , activation ='relu', dtype ='float64') ,\n",
        "            layers.Dense(10 , activation ='relu', dtype ='float64') ,\n",
        "            layers.Softmax(dtype ='float64')])\n",
        "\n",
        "    # Compiler le modele pour l’ entrainement\n",
        "    mlp3c.compile( optimizer ='SGD',loss = tf.keras.losses.SparseCategoricalCrossentropy(),metrics =['accuracy'])\n",
        "\n",
        "    result = training(mlp3c,data_set,epochs=epoque)\n",
        "    figure(result , \" Apprentissage d’un MLP a 2 couche avec abandon pour la classification des signaux sonores \")\n",
        "\n",
        "    mlp3c.save('modeles/mlp3')\n",
        "\n",
        "  elif mode==4:\n",
        "\n",
        "    model_choix = tf.keras.Sequential([\n",
        "            layers.Dense(512 , activation ='relu', dtype ='float64') ,\n",
        "            layers.Dense(128 , activation ='relu', dtype ='float64') ,\n",
        "            layers.Dense(10 , activation ='relu', dtype ='float64') ,\n",
        "            layers.Softmax(dtype ='float64')])\n",
        "\n",
        "    # Compiler le modele pour l’ entrainement\n",
        "    model_choix.compile( optimizer ='SGD',loss = tf.keras.losses.SparseCategoricalCrossentropy(),metrics =['accuracy'])\n",
        "\n",
        "    result = training(model_choix,data_set,epochs=epoque)\n",
        "    figure(result , \" Apprentissage d’un MLP a 2 couche avec abandon pour la classification des signaux sonores \")\n",
        "\n",
        "    model_choix.save('modeles/model_choix')\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "F0MW7f7-fvbI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}